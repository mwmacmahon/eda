{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Database Storage Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds targeted data directory as into project sqlite database tables \"raw_data\" and \"metadata\".\n",
    "\n",
    "Data is processed just enough to save the structure of the directory (e.g., file_id, experiment_id, run_id). Optionally, one can add an \"experiment_alias\" tag, unique to this script, to metadata of all files stored by this script. This can be overwritten at any time by re-running with the metadata overwrite_flag keyword below set to \"yes\" or \"force\".\n",
    "\n",
    "For visualizing and processing data, check for a \"process_experiment_in_database.ipynb\" file, probably in the same directory as this script.\n",
    "\n",
    "As a result of the minimal processing, there is probably no reason to re-run this script unless one wishes to change the experiment_alias or reflect new changes to the data directory. In this case, make sure to check the overwrite_flag keyword argument below to ensure the database is properly updated.\n",
    "\n",
    "---\n",
    "TABLE: raw_data\n",
    "\n",
    "new columns (in addition to csv columns) added by this script:\n",
    "- file_id (new 1st column)\n",
    "- file_row (new 2nd column)\n",
    "---\n",
    "TABLE: metadata\n",
    "\n",
    "table columns: file_id, key, value\n",
    "\n",
    "new k:v pairs (in addition to those in csv header) added by this script:\n",
    "- file_id:  id unique to this file\n",
    "- experiment_id:  id unique to this directory\n",
    "- experiment_alias:  optional metadata tag for all files added by this script\n",
    "- run_id:         id assigned to each folder of csv's by this script\n",
    "- index_2d:       optional file order within a run, taken from filename after \"Ind_\" if present\n",
    "- filepath:       filepath (absolute)\n",
    "- relative_filepath:  filepath (relative to this script's directory)\n",
    "- last_modified:  csv file-last-modified timestamp\n",
    "---\n",
    "id value dependencies:\n",
    "- file_id derived from start time and filename (NOT filepath)\n",
    "- experiment_id derived from this script's directory\n",
    "---\n",
    "assumptions made by script:\n",
    "- Data is from __June 2019 or later__ (needs timestamps, header height, labtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_alias = \"RepTestRSA_181102\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "\n",
    "import eda.analysis.dataframe_plotting as dfplot\n",
    "import eda.analysis.dataframe_processing as dfproc\n",
    "import eda.data_io.csv_to_dataframe as csv2df\n",
    "import eda.data_io.sqlite_io as sqlio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# REQUIRED: CSV data & sqlite database directories\n",
    "parent_dir = ('..\\\\..\\\\used_data')\n",
    "db_parent_dir =  '..\\\\..\\\\..\\\\..\\\\database\\\\'\n",
    "db_filepath = db_parent_dir + 'dnpdb.sqlite'\n",
    "\n",
    "# REQUIRED: source csv format information\n",
    "delimiter = '\\t'\n",
    "trailing_delimiters = True  # rows end in delimiters\n",
    "num_headerlines = 9\n",
    "column_names_row = 0  # NOT counting skipped lines from num_headerlines\n",
    "pandas_read_csv_kwargs = {\n",
    "     'skiprows': num_headerlines,\n",
    "     'header': column_names_row,\n",
    "     'names': None,\n",
    "     'delimiter': delimiter,\n",
    "}\n",
    "if trailing_delimiters:  # needed to avoid problems\n",
    "    pandas_read_csv_kwargs['index_col'] = False\n",
    "\n",
    "# REQUIRED: filename key for data files, will load only these\n",
    "filename_key = '.dat'\n",
    "\n",
    "# REQUIRED: criteria for grouping runs\n",
    "run_criteria = 'directory'\n",
    "\n",
    "# OPTIONAL: filepath parsing rules\n",
    "# DEFAULT SEARCH TERMS AND SEARCH RULES:\n",
    "# 1. If first string found, register second string as\n",
    "#    tag containing third string/value\n",
    "#        e.g. if keyword_list contains (\"warmup\", \"Warmup?\", \"Yes\"):\n",
    "#             \"...warmup...\" -> {\"Warmup?\": \"Yes\"}\n",
    "this_element_keyword_list = [\n",
    "]\n",
    "# 2. Grab next element(s) if this one CONTAINS first string,\n",
    "#    tag next element(s) as second string(s)\n",
    "#        e.g. \"..._Ind_3_...\" -> {\"FastScanIndex\": 3}\n",
    "#        e.g. \"..._2Dscan_MirrorY_MirrorZ_...\"\n",
    "#                 -> {\"SecondScanType\": \"MirrorY\",\n",
    "#                     \"FirstScanType\": \"MirrorZ\"}\n",
    "next_element_keyword_list = [\n",
    "    (   \"Ind\", \"SecondScanIndex\"),\n",
    "    (\"2Dscan\", [\"SecondScanType\", \"FirstScanType\"])\n",
    "]\n",
    "\n",
    "# 3. Grab this element if it CONTAINS first string,\n",
    "#    tag remainder as second string\n",
    "#        e.g. \"..._30K_...\" -> {\"SetTemperature\": 30}\n",
    "in_this_element_keyword_list = [\n",
    "    (    \"mT\", \"Magnetic Field (mT)\"),\n",
    "    (     \"T\", \"Magnetic Field (T)\"),\n",
    "    (     \"K\", \"Set Temperature (K)\"),\n",
    "    (    \"nm\", \"Wavelength (nm)\"),\n",
    "    (    \"ps\", \"Delay Time (ps)\"),\n",
    "    (     \"V\", \"Voltage (V)\"),\n",
    "    (   \"rep\", \"Reps per Step (#)\"),\n",
    "    (    \"uW\", \"Pump Power (uW)\"),\n",
    "    (\"uWPump\", \"Pump Power (uW)\"),\n",
    "    (    \"mW\", \"Pump Power (mW)\"),\n",
    "    (\"mWPump\", \"Pump Power (mW)\"),\n",
    "    (     \"x\", \"SecondScanCoord\"),\n",
    "]\n",
    "\n",
    "def process_secondscancoord(metadata_dict):\n",
    "    if {'SecondScanType', 'SecondScanCoord'}.issubset(metadata_dict.keys()):\n",
    "        key = metadata_dict['SecondScanType']\n",
    "        metadata_dict[key] = metadata_dict['SecondScanCoord']\n",
    "def consolidate_aliases_for_b_external(metadata_dict):\n",
    "    if {'SecondScanType', 'SecondScanCoord'}.issubset(metadata_dict.keys()):\n",
    "        if (metadata_dict['SecondScanType'] == 'Magnetic Field (T)'\n",
    "                or metadata_dict['SecondScanType'] == 'BExternal'):\n",
    "            metadata_dict['SecondScanType'] = 'Magnetic Field (mT)'\n",
    "            metadata_dict['SecondScanCoord'] *= 1000.0\n",
    "    if 'BExternal' in metadata_dict.keys():\n",
    "        metadata_dict['Magnetic Field (T)'] = metadata_dict['BExternal']\n",
    "        del metadata_dict['BExternal']\n",
    "    if 'Magnetic Field (T)' in metadata_dict.keys():\n",
    "        metadata_dict['Magnetic Field (mT)'] = \\\n",
    "            1000.0 * metadata_dict['Magnetic Field (T)']\n",
    "        del metadata_dict['Magnetic Field (T)']\n",
    "def consolidate_aliases_for_pump_power(metadata_dict):\n",
    "    if 'Pump Power (uW)' in metadata_dict.keys():\n",
    "        metadata_dict['Pump Power (mW)'] = \\\n",
    "            1e-3 * metadata_dict['Pump Power (uW)']\n",
    "        del metadata_dict['Pump Power (uW)']\n",
    "def handle_standalone_1d_scans(metadata_dict):\n",
    "    if 'SecondScanIndex' not in metadata_dict:\n",
    "        try:  # use persistent attribute of this function object\n",
    "            handle_standalone_1d_scans.counter += 1\n",
    "        except AttributeError:\n",
    "            handle_standalone_1d_scans.counter = 1\n",
    "        custom_ssi = handle_standalone_1d_scans.counter - 1\n",
    "        metadata_dict['Run ID'] = -1\n",
    "        metadata_dict['SecondScanIndex'] = custom_ssi\n",
    "        metadata_dict['SecondScanType'] = \"None\"\n",
    "        metadata_dict['SecondScanCoord'] = 0\n",
    "#         metadata_dict['Magnetic Field (mT)'] = 0  # fixes issue later, but why?\n",
    "        # get scan type, assume form \"[type]_x_to_y.dat\n",
    "        scan_type = metadata_dict['Filepath'].split('_')[-4]\n",
    "        metadata_dict['FirstScanType'] = scan_type\n",
    "def ensure_integer_index_2d(metadata_dict):\n",
    "    if 'SecondScanIndex' in metadata_dict:\n",
    "        metadata_dict['SecondScanIndex'] = int(metadata_dict['SecondScanIndex'])\n",
    "\n",
    "# full metadata processing:\n",
    "parsing_keyword_lists = [this_element_keyword_list,\n",
    "                         next_element_keyword_list,\n",
    "                         in_this_element_keyword_list]\n",
    "metadata_processing_fcns = [process_secondscancoord,\n",
    "                            consolidate_aliases_for_b_external,\n",
    "                            consolidate_aliases_for_pump_power,\n",
    "                            handle_standalone_1d_scans,\n",
    "                            ensure_integer_index_2d]\n",
    "\n",
    "# # alternatively, minimal processing version:\n",
    "# parsing_keyword_lists = [[],[(\"Ind\",\"SecondScanIndex\")],[]]\n",
    "# metadata_processing_fcns = []\n",
    "\n",
    "metadata_filter_fcns = []\n",
    "metadata_tag_to_column_list = []\n",
    "dataframe_processing_fcns = []\n",
    "\n",
    "# def handle_standalone_1d_scans(metadata_dict):\n",
    "#     if 'SecondScanIndex' not in metadata_dict:\n",
    "#         try:  # use persistent attribute of this function object\n",
    "#             handle_standalone_1d_scans.counter += 1\n",
    "#         except AttributeError:\n",
    "#             handle_standalone_1d_scans.counter = 1\n",
    "#         custom_ssi = handle_standalone_1d_scans.counter - 1\n",
    "#         metadata_dict['Run ID'] = -1\n",
    "#         metadata_dict['SecondScanIndex'] = custom_ssi\n",
    "# def ensure_integer_index_2d(metadata_dict):\n",
    "#     if 'SecondScanIndex' in metadata_dict:\n",
    "#         metadata_dict['SecondScanIndex'] = int(metadata_dict['SecondScanIndex'])\n",
    "# metadata_processing_fcns = [handle_standalone_1d_scans,\n",
    "#                             ensure_integer_index_2d]\n",
    "\n",
    "file_df_list, file_metadata_list = \\\n",
    "    csv2df.process_directory_csvs_to_dataframes(\n",
    "        parent_dir, filename_key, run_criteria,\n",
    "        pandas_read_csv_kwargs,\n",
    "        parsing_keyword_lists,\n",
    "        metadata_processing_fcns,\n",
    "        metadata_filter_fcns,\n",
    "        metadata_tag_to_column_list,\n",
    "        dataframe_processing_fcns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scancoord</th>\n",
       "      <th>lockin2x</th>\n",
       "      <th>lockin1x</th>\n",
       "      <th>lockin2r</th>\n",
       "      <th>lockin1r</th>\n",
       "      <th>laserpower</th>\n",
       "      <th>cwetalon</th>\n",
       "      <th>lockin3x</th>\n",
       "      <th>lockin3r</th>\n",
       "      <th>lockin4x</th>\n",
       "      <th>lockin4r</th>\n",
       "      <th>lockin5x</th>\n",
       "      <th>lockin5r</th>\n",
       "      <th>lasercomponent1</th>\n",
       "      <th>lasercomponent2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>labtime</th>\n",
       "      <th>file_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.0179</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.01845</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>-0.0081</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>-0.26288</td>\n",
       "      <td>0.26318</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.021</td>\n",
       "      <td>1.578671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scancoord  lockin2x  lockin1x  lockin2r  lockin1r  laserpower  cwetalon  \\\n",
       "0       -0.3   -0.0179  0.000873   0.01845  0.000887      -0.134     0.769   \n",
       "\n",
       "   lockin3x  lockin3r  lockin4x  lockin4r  lockin5x  lockin5r  \\\n",
       "0  0.000628  0.000286   -0.0081    0.0145  -0.26288   0.26318   \n",
       "\n",
       "   lasercomponent1  lasercomponent2  temperature   labtime  file_index  \n",
       "0            0.003            0.001       10.021  1.578671           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full df first line for column reference\n",
    "orig_colnames = list(file_df_list[0])\n",
    "file_df_list[1].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata_df_list = []\n",
    "for file_df, file_metadata in zip(file_df_list,\n",
    "                                  file_metadata_list):\n",
    "    updated_metadata = sqlio.get_updated_metadata_dict(file_metadata,\n",
    "                                                       experiment_alias)\n",
    "    file_metadata_df = sqlio.dict_to_two_column_df(updated_metadata)\n",
    "    file_df.reset_index(inplace=True)\n",
    "    file_df.rename(index=str, columns={'index': 'file_row'}, inplace=True)\n",
    "    file_df.insert(0, 'file_id', updated_metadata['file_id'])\n",
    "    file_metadata_df.insert(0, 'file_id', updated_metadata['file_id'])\n",
    "    file_metadata_df_list.append(file_metadata_df)\n",
    "    del file_df['file_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>file_row</th>\n",
       "      <th>scancoord</th>\n",
       "      <th>lockin2x</th>\n",
       "      <th>lockin1x</th>\n",
       "      <th>lockin2r</th>\n",
       "      <th>lockin1r</th>\n",
       "      <th>laserpower</th>\n",
       "      <th>cwetalon</th>\n",
       "      <th>lockin3x</th>\n",
       "      <th>lockin3r</th>\n",
       "      <th>lockin4x</th>\n",
       "      <th>lockin4r</th>\n",
       "      <th>lockin5x</th>\n",
       "      <th>lockin5r</th>\n",
       "      <th>lasercomponent1</th>\n",
       "      <th>lasercomponent2</th>\n",
       "      <th>temperature</th>\n",
       "      <th>labtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'tzdTgY4JcTf7MegMM1dmfw=='</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.02725</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>-0.00400</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>-0.29582</td>\n",
       "      <td>0.29616</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.017</td>\n",
       "      <td>1.631405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'tzdTgY4JcTf7MegMM1dmfw=='</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.04240</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.776</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>-0.00505</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>-0.29696</td>\n",
       "      <td>0.29730</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>10.015</td>\n",
       "      <td>2.846728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_id  file_row  scancoord  lockin2x  lockin1x  \\\n",
       "0  b'tzdTgY4JcTf7MegMM1dmfw=='         0       -0.3    0.0220  0.001026   \n",
       "1  b'tzdTgY4JcTf7MegMM1dmfw=='         1        0.0    0.0411  0.000944   \n",
       "\n",
       "   lockin2r  lockin1r  laserpower  cwetalon  lockin3x  lockin3r  lockin4x  \\\n",
       "0   0.02725  0.001008      -0.137     0.769  0.000712  0.000731  -0.00400   \n",
       "1   0.04240  0.000953      -0.140     0.776 -0.000026  0.000822  -0.00505   \n",
       "\n",
       "   lockin4r  lockin5x  lockin5r  lasercomponent1  lasercomponent2  \\\n",
       "0   0.00535  -0.29582   0.29616            0.311            0.001   \n",
       "1   0.00500  -0.29696   0.29730            0.006           -0.330   \n",
       "\n",
       "   temperature   labtime  \n",
       "0       10.017  1.631405  \n",
       "1       10.015  2.846728  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df_list[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file_id', 'experiment_id', 'experiment_alias', 'run_id', 'index_2d', 'filepath', 'relative_filepath', 'last_modified', 'Delay Time (ps)', 'Wavelength (nm)', 'Set Temperature (K)', 'SecondScanType', 'FirstScanType', 'SecondScanCoord', 'Acquisition Program', 'Lockin Sensitivities (V)', 'Lockin Time Constants (s)', 'Lockin Reference Frequencies (Hz)', 'Lockin Reference Phases (degrees)', 'Scan Start', 'Scan End', 'NumReps']\n"
     ]
    }
   ],
   "source": [
    "print(list(file_metadata_df_list[0].key))  # print() for vertical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG TOOL: change row, remove preprocessed metadata from third file metadata\n",
    "file_metadata_df_list[2] = file_metadata_df_list[2][\n",
    "    file_metadata_df.key.isin(['file_id', 'experiment_id', 'experiment_alias',\n",
    "                               'run_id', 'index_2d', 'filepath',\n",
    "                               'relative_filepath', 'last_modified',\n",
    "                               'Acquisition Program',\n",
    "                               'Lockin Sensitivities (V)',\n",
    "                               'Lockin Time Constants (s)',\n",
    "                               'Lockin Reference Frequencies (Hz)',\n",
    "                               'Lockin Reference Phases (degrees)',\n",
    "                               'Scan Start', 'Scan End'])\n",
    "    ]\n",
    "file_metadata_df_list[2].value.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to database and update tables 'raw_data', 'metadata_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connect(db_filepath)  # make sure to close()!\n",
    "sqlio.create_missing_tables(conn)  # database needs tables raw_data, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-96debb166be0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile_df\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_df_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     if sqlio.add_file_df_to_raw_data_if_missing(file_df, conn,\n\u001b[1;32m----> 4\u001b[1;33m                                                 overwrite_flag='warn'):\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mnum_file_additions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Added %d files to table 'raw_data'!\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_file_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\source\\repos\\eda\\eda\\data_io\\sqlite_io.py\u001b[0m in \u001b[0;36madd_file_df_to_raw_data_if_missing\u001b[1;34m(file_df, conn, overwrite_flag)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[0mfile_file_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[0mfile_num_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mnum_rows_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_rows_for_file_id_in_raw_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_file_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_rows_found\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# easiest case, just add file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mfile_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raw_data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'append'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\source\\repos\\eda\\eda\\data_io\\sqlite_io.py\u001b[0m in \u001b[0;36mnum_rows_for_file_id_in_raw_data\u001b[1;34m(file_id, conn)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \"\"\"\n\u001b[0;32m     89\u001b[0m     \u001b[0mqparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# must be tuple for DB-API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mqdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0mnum_rows_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\eda\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m    312\u001b[0m     return pandas_sql.read_query(\n\u001b[0;32m    313\u001b[0m         \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\eda\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m         \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1469\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\eda\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1427\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "num_file_additions = 0\n",
    "for file_df in file_df_list:\n",
    "    if sqlio.add_file_df_to_raw_data_if_missing(file_df, conn,\n",
    "                                                overwrite_flag='warn'):\n",
    "        num_file_additions += 1\n",
    "print(\"Added %d files to table 'raw_data'!\" % num_file_additions)\n",
    "\n",
    "num_metadata_additions = 0\n",
    "for metadata_df in file_metadata_df_list:\n",
    "    if sqlio.update_metadata_table_from_metadata_df(metadata_df, conn,\n",
    "                                                    overwrite_flag='warn'):\n",
    "        num_metadata_additions += 1\n",
    "print(\"Updated/added %d files in table 'metadata'!\" % num_metadata_additions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG TOOL: block running close command\n",
    "# raise Exception(\"don't close yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always run at end!\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG TOOL: add rows to a metadata_df\n",
    "# ind = 0\n",
    "# file_metadata_df_list[ind] = \\\n",
    "#     file_metadata_df_list[ind].append(file_metadata_df_list[ind].iloc[-1])\n",
    "# file_metadata_df_list[ind].iloc[-1].key = \"what\"\n",
    "# file_metadata_df_list[ind].iloc[-1].value = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG TOOL: check what exists in table raw_data\n",
    "# file_id = file_metadata_df_list[0].file_id.iloc[0]\n",
    "# query = \"\"\"SELECT *\n",
    "#            FROM raw_data\n",
    "#            WHERE file_id = ?\"\"\"\n",
    "# qdf = pd.read_sql_query(query, conn, params=(file_id,))\n",
    "# qdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG TOOL: check what exists in table metadata\n",
    "# file_id = file_metadata_df_list[0].file_id.iloc[0]\n",
    "# query = \"\"\"SELECT *\n",
    "#            FROM metadata\n",
    "#            WHERE file_id = ?\"\"\"\n",
    "# qdf = pd.read_sql_query(query, conn, params=(file_id,))\n",
    "# qdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG TOOL: DELETE ALL ROWS FROM raw_data\n",
    "# query = \"\"\"DELETE FROM raw_data;\"\"\"\n",
    "# conn.execute(query)\n",
    "# conn.commit()\n",
    "# query = \"\"\"VACUUM;\"\"\"\n",
    "# conn.execute(query)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG TOOL: DELETE ALL ROWS FROM metadata\n",
    "# query = \"\"\"DELETE FROM metadata;\"\"\"\n",
    "# conn.execute(query)\n",
    "# conn.commit()\n",
    "# query = \"\"\"VACUUM;\"\"\"\n",
    "# conn.execute(query)\n",
    "# conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "487px",
    "width": "750px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
